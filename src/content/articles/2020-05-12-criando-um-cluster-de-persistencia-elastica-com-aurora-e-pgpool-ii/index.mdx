---
slug: criando-um-cluster-de-persistencia-elastica-com-aurora-e-pgpool-ii
title: "Criando um Cluster El√°stico de PostgreSQL usando Amazon Aurora e pgpool-II"
description: "Uma infraestrutura el√°stica √© um alivio para um time de tecnologia, o poupando da  necessidade de 'downtime' ao modificar o seu tamanho."
type: "story"
categories: ["Infraestrutura", "Persist√™ncia"]
ogimage: "./ogimage.png"
twitterimage: "./twitterimage.png"
---

import PostNote from 'atoms/PostNote/PostNote'
import Link from 'atoms/Link/Link'

![Foto por Jakob Owens do Unsplash](./ogimage.png)

Um problema bom que empresas de tecnologia em r√°pido crescimento podem ter √© o de que a utiliza√ß√£o da CPU do banco de dados est√° atingindo n√≠veis muito altos, e precisa ser trocada toda semana. Essa √© a hist√≥ria de como n√≥s do Z√© Delivery, depois de ver uma apresenta√ß√£o da MaxiMilhas (obrigado, pessoal!) no AWS Summit 2018 em S√£o Paulo, substitu√≠mos nossa inst√¢ncia √∫nica ‚Äî sozinha, coitada, l√° no console do RDS ‚Äî de PostgreSQL por um cluster de Amazon Aurora atr√°s de um load balancer com inst√¢ncias de pgpool-II.

Primeiro s√≥ gostaria de levantar algumas informa√ß√µes sobre o nosso neg√≥cio e sobre a situa√ß√£o que est√°vamos enfrentando para que as nossas decis√µes de arquitetura fiquem mais claras.

- Nosso neg√≥cio se parece bastante com um marketplace, ent√£o as chamadas recebidas pela nossa API apresentam um vi√©s para as leituras, e n√£o para as escritas. Essa solu√ß√£o provavelmente n√£o vai funcionar (ou vai ser de nenhuma utilidade) caso a distribui√ß√£o das suas chamadas tenha um vi√©s para a escrita;
- Nossa API √© [serverless](https://aws.amazon.com/serverless/) usando o AWS Lambda e tem picos de mais de 500 execu√ß√µes concorrentes;
- N√≥s precisamos da extens√£o de sistema de informa√ß√£o geogr√°fica do PostgreSQL;
- Aurora Serverless para PostgreSQL tinha acabado de ser lan√ßado na √©poca;

Agora explicarei de uma forma resumida as principais caracter√≠sticas do Amazon Aurora e do pgpool-II para resolver problemas de escala ‚Äî junto com as recomenda√ß√µes da AWS ‚Äî que justificam nossas decis√µes de projeto.
Depois, ent√£o, vou descrever nossa stack el√°stica levantando algumas coisas que aprendemos desde que colocamos ela em produ√ß√£o.

## Amazon Aurora
Um cluster Amazon Aurora √© um banco de dados relacional compat√≠vel com PostgreSQL que consiste em um grupo de uma a dezesseis inst√¢ncias ligado a um sistema de armazenamento distribu√≠do ‚Äî tolerante a falhas e com recupera√ß√£o autom√°tica ‚Äî que se estende por v√°rias zonas de disponibilidade com uma c√≥pia dos dados em cada.
![Aurora](./aurora.png)
A caracter√≠stica que vamos nos ater ‚Äî sem desmerecer todas as outras de disponibilidade e resili√™ncia ‚Äî √© a sincroniza√ß√£o das r√©plicas de leitura e a sua f√°cil cria√ß√£o.

## Aurora Read Replicas
Aurora Replicas s√£o endpoints de leitura independentes em um cluster de Amazon Aurora que a AWS balanceia a carga convenientemente em um endpoint √∫nico de leitura. Voc√™ pode ter at√© 15 replicas distribu√≠das entre as zonas de disponibilidade do cluster. O atraso entre a escrita e a disponibilidade nas r√©plicas de leitura √© da escala de milissegundos ‚Äî menos de 100ms no nosso caso.

<PostNote isBlue>
    <p className="PostNote__content">
        Aurora Replicas funcionam bem para escalar buscas em banco de dados porque elas s√£o totalmente dedicadas para opera√ß√µes de leitura no seu cluster de armazenamento. O Banco de dados principal gerencia as opera√ß√µes de escrita. O cluster de armazenamento √© compartilhado entre todas as inst√¢ncias em seu cluster de banco de dados. Portanto, nenhum trabalho adicional √© necess√°rio para replicar uma copia dos dados para cada Aurora Replica. Em contraste, cada r√©plica de leitura do PostgreSQL precisa aplicar, em uma √∫nica thread, todas as opera√ß√µes de escritas da instancia principal do banco de dados em seu armazenamento local. Essa limita√ß√£o pode afetar a capacidade de uma r√©plica de leitura PostgreSQL de suportar grandes volumes de tr√°fegos de escrita.
    </p>
    <Link
        className="PostNote__link"
        to="https://developer.mozilla.org/en-US/docs/Web/HTML">
        User Guide for Aurora
    </Link>
</PostNote>

Alem disso tudo, voc√™ pode criar um auto-scalling group que controla o numero de inst√¢ncias de Aurora Replicas no seu grupo de leitura baseado em utiliza√ß√£o de CPU ou n√∫mero de conex√µes. Com isso a sua capacidade de leitura de dados pode crescer at√© a ‚Äî colossal escala de ‚Äî 720 n√∫cleos de um processador Intel Xeon Platinum de 2,5 GHz, 5.376 GiB de mem√≥ria RAM, 350 Gbps de performance de rede.

## Recomenda√ß√µes da AWS sobre aumentar a capacidade de bancos de dados
J√° tivemos que escalar verticalmente nossa inst√¢ncia de banco de dados duas vezes.
O banco de dados ficou cinco minutos sem responder ‚Äî e isso √© bastante tempo.
Ficamos ansiosos, com medo de alguma coisa dar errado e precisarmos restaurar os dados de algum backup.
Por isso n√£o gostamos de escalar o banco verticalmente.
Por mais que tenhamos nos sa√≠do bem das duas experi√™ncias, n√£o √© algo que queremos ter que fazer todas as quartas, quintas e sextas-feiras, alem dos finais de semana.
Por isso que optamos por uma estrat√©gia de escala horizontal, onde podemos aumentar a capacidade do cluster de bancos de dados sem ficar um segundo desconectado.

O [AWS Database Blog](https://aws.amazon.com/blogs/database/) √© um bom lugar para responder perguntas sobre bancos de dados, mesmo n√£o usando solu√ß√µes de infraestrutura da Amazon.
Foi l√° que fomos buscar responder nossas perguntas ap√≥s assistir a palestra de como a MaxiMilhas resolveu seu problema de escala de banco de dados.

### Escalando Horizontalmente
No artigo ["Scaling Your Amazon RDS Instance Vertically and Horizontally"](https://aws.amazon.com/blogs/database/scaling-your-amazon-rds-instance-vertically-and-horizontally/) confirmamos a id√©ia de usar o Amazon Aurora.
A Amazon √© bem clara quanto a maneira de escalar horizontalmente: <b>use r√©plicas de leitura e divida suas consultas entre as de escrita e as de leitura.</b>
As op√ß√µes para dividir as consultas entre escrita e leitura s√£o duas: usar algum m√≥dulo na sua camada de persist√™ncia para fazer a divis√£o ou instalar um balanceador de carga L7.

### Dividir as consultas na sua camada de persist√™ncia
Dividir as consultas na camada de persist√™ncia resultaria em cada execu√ß√£o de AWS Lambda abrir duas conex√µes com o banco de dados. Isso n√£o √© ideal mas seria um pre√ßo a se pagar para solucionar o problema de forma r√°pida sem colocar novas pe√ßas moveis na infraestrutura. O maior problema dessa solu√ß√£o seria, no nosso caso, n√£o ter uma √∫nica transa√ß√£o e sim duas, uma para a escrita e uma para a leitura. Isso seria uma d√≠vida t√©cnica grande demais, ent√£o resolvemos analisar a segunda op√ß√£o.

### Balanceador de carga L7
Um balanceador de carga L7 ou <i>layer 7</i> opera na s√©tima camada do modelo [OSI](https://pt.wikipedia.org/wiki/Modelo_OSI#7_-_Camada_de_Aplica√ß√£o), a camada de aplica√ß√£o.
√â uma pe√ßa de infraestrutura que divide as requisi√ß√µes a um determinado IP baseado em seu conte√∫do ‚Äî no nosso caso no conte√∫do da consulta SQL.
O balanceador de carga L7 pode enviar todas as consultas iniciadas por `SELECT` para um determinado IP e as iniciadas por `UPDATE`, `CREATE` e `DELETE` para outro.

Isso nos ajudou a responder quase todas as d√∫vidas que tivemos ao voltar do <i>AWS Summit</i>.
Precis√°vamos escalar nossa camada de persist√™ncia horizontalmente usando um balanceador de carga L7.
S√≥ nos restou uma d√∫vida, pois todos os exemplos e softwares apresentados no AWS Summit e no AWS Database Blog eram para MySQL: N√£o usamos MySQL, ser√° que existe algo como o ProxySQL e o MySQL Proxy para PostgreSQL?

## pgpool-II
O [pgpool-II](https://github.com/pgpool/pgpool2) √© um middleware que funciona entre inst√¢ncias de PostgreSQL e seus clientes.
Ele √© um software bastante completo para a manuten√ß√£o de clusters de PostgreSQL com alta disponibilidade, mas, como o Amazon Aurora j√° implementa v√°rias de suas fun√ß√µes nativamente, vamos nos ater no enfileiramento (queuing), represamento (pooling) de conex√µes e no balanceamento de requisi√ß√µes.

### Enfileiramento de Conex√µes
Existe um limite do n√∫mero de conex√µes que podem ser feitas a um banco de dados simultaneamente e sua performance tem alta correla√ß√£o com este n√∫mero ‚Äî para entender melhor recomendo [ler o que Brett Wooldridge escreveu sobre o assunto](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing).
Para melhorar a performance da camada de persist√™ncia o pgpool-II mant√™m o n√∫mero de conex√µes em um valor m√°ximo, todas as conex√µes subsequentes devem esperar numa fila para conectar com o banco de dados.

### Represamento de Conex√µes
O pgpool-II salva as conex√µes com as inst√¢ncias de PostgreSQL (servidores) e as reusa toda vez que uma nova conex√£o com as mesmas propriedades (como senha, banco de dados) √© feita.
Com isso ela reduz o tempo de fazer essa nova conex√£o e aumenta a capacidade de tr√°fego de informa√ß√µes do cluster.

### Balanceamento de Requisi√ß√µes
Se os dados do banco de dados est√£o replicados, executar consulta de leitura (`SELECT`) em qualquer uma das inst√¢ncias, tanto a principal como as replicas, ter√° o mesmo resultado.
Por causa disso o pgpool-II usa as inst√¢ncias de replica√ß√£o para distribuir as consultas de leitura entre v√°rias inst√¢ncias de replica√ß√£o, aumentando ‚Äî novamente ‚Äî a capacidade de tr√°fego de informa√ß√µes do cluster.

Juntando a facilidade de gerenciamento do Amazon Aurora e o balanceamento de requisi√ß√µes do pgpool-II pudemos ent√£o montar nossa camada de persist√™ncia el√°stica.

## A Camada de Persist√™ncia El√°stica do Z√© Delivery
![ze-persistence-layer](./ze-persistence-layer.png)
A estrutura que est√° hoje em produ√ß√£o √© a ilustrada acima. 
Consiste em um balanceador de carga L4 (<i>Network Load Balancer</i>) distribuindo as requisi√ß√µes em um grupo de Auto Scaling com as inst√¢ncias de pgpool-II.
Estas se conectam aos endpoints padr√µes de escrita e leitura do cluster Amazon Aurora.
Configuramos o cluster para adicionar novas r√©plicas quando a CPU m√©dia das inst√¢ncias de leitura passa de 50% ‚Äî subir uma inst√¢ncia a mais sem necessidade n√£o √© algo caro, desde que elas sejam destru√≠das assim que necess√°rio ‚Äî e o Auto Scaling dos pgpool-II √© baseado no tr√°fego de rede m√©dio do grupo.

Um bom lugar para come√ßar a construir isso √© [clonando este reposit√≥rio de exemplo da AWS](https://github.com/aws-samples/amazon-aurora-pgpool-example) e n√£o esquecer de seguir as [recomenda√ß√µes na documenta√ß√£o do pgpool-II para o uso com Amazon Aurora](https://www.pgpool.net/docs/latest/en/html/example-aurora.html).
O nosso processo de amadurecimento levou cerca de dois meses e creio que essas sejam as coisas mais importantes que aprendemos:

- A utiliza√ß√£o de CPU das inst√¢ncias do pgpool-II tem pouco significado, o recurso mais cr√≠tico para elas √© o tr√°fego de rede. Por isso que optamos por inst√¢ncias do tipo <b>m5</b>. Esta apresenta uma performance de rede melhor que as <b>t3</b>;
- N√£o enviar consultas de leitura para a inst√¢ncia prim√°ria do cluster. Ela j√° vai ter trabalho o suficiente com as escritas. Alem disso, ela n√£o consegue escalar horizontalmente, ent√£o, colocar a carga extra far√° necess√°rio escalar verticalmente mais cedo;
- Criar uma imagem de disco (AMI) ao inv√©s de baixar e instalar todos os bin√°rios nas inst√¢ncias de pgpool-II todas as vezes que s√£o criadas. N√≥s n√£o fizemos isso e um dia o http://pgpool.net/ parou de responder. Com isso todas as nossas novas inst√¢ncias criadas (e v√°rias foram criadas pois o balanceador de carga n√£o parava de pedir mais) n√£o funcionavam;
- N√£o usar custom-endpoints do Amazon Aurora. Eles levam muito tempo para ficarem dispon√≠veis depois de qualquer altera√ß√£o e o pgpool-II vai desistir de conectar com o cluster antes do endpoint ficar dispon√≠vel;
- Enviar os logs do pgpool-II para um agregador de logs ‚Äî no caso do CloudWatch basta instalar o awslogs (`yum -y install awslogs`) e configurar a rota√ß√£o de logs para que o disco das inst√¢ncias n√£o fique cheio;
- Criar um <i>cron script</i> para reiniciar as inst√¢ncias de pgpool-II que se desconectarem do cluster.

Essa estrutura funciona de maneira est√°vel em produ√ß√£o sem nenhuma altera√ß√£o desde setembro de 2019. Ela j√° suportou os picos de acesso durante as f√©rias de ver√£o e carnaval sem precisarmos atuar na infraestrutura de persist√™ncia durante os eventos. Estamos bastante satisfeitos com o que ela j√° fez para o Z√© Delivery. üçª

Espero ter ajudado, caso tenha alguma d√∫vida n√£o deixe de entrar em contato escrevendo um coment√°rio aqui no Medium ou pelo meu twitter: [@flpStrri](https://twitter.com/flpStrri).
